/*
##################################################################################

	Written by David Brandyberry, University of Illinois at Urbana-Champaign
	Please contact (brandyb2@illinois.edu) before distributing
	Last Updated September 2016

##################################################################################
*/
#include "Refiner.h"
#include "Problem.h"
#include "Mesh.h"
#include "BoundaryObject.h"
#include "Utilities.h"
#include "elem.h"
#include <algorithm>



/*
 * The Big 3
 * The constructor takes the problem that will be partitioned
 * Destructor doesn't do anything
 * Copy constructor copies over the problem pointer
 */
Refiner::Refiner(Problem* prob)
	: _prob(prob)
{}
Refiner::Refiner()
{}
Refiner::~Refiner()
{}
Refiner::Refiner(const Refiner& other)
{
	_prob = other.get_prob();
}




/*
 * Returns the Mesh that is being refined
 */
Mesh* Refiner::get_mesh() const
{
	return _prob->get_mesh();
}




/*
 * The main interface with this class. Will be called to refine the mesh
 * Note: This may be overridden in derived classes so this may not be what actually runs
 */
void Refiner::refine()
{
	// If the mesh hasn't beeen refined before, set some things
	initialize_mesh_refinement();

	// Generate the list of refined elements
	std::set<id_type> refined_elements;
	generate_refine_set(refined_elements);

	// Refine the elements
	refine_elements(refined_elements);

	// Determine the new node_elem structure
	get_mesh()->generate_node_elem();

	// Find all of the hanging nodes generated by this refinement
	get_mesh()->detect_hanging_nodes();

	// Interpolate the solution to the new nodes and quadrature points
	interpolate_solution();

	// Update the number of times the mesh has been refined
	get_mesh()->_mesh_topology++;
}




/*
 * If the mesh hasn't beeen refined before, set some things
 */
void Refiner::initialize_mesh_refinement()
{
 	if (get_mesh()->get_mesh_topology() == 0)
	{
		get_mesh()->_elem_parents.resize(get_mesh()->n_local_elem());
		get_mesh()->_p_level.resize(get_mesh()->n_local_elem());
	 	std::fill(get_mesh()->_elem_parents.begin(), get_mesh()->_elem_parents.end(), -1);
	 	std::fill(get_mesh()->_p_level.begin(), get_mesh()->_p_level.end(), 0);
	}
}




/*
 * Given a set of new nodes, returns the owner of the refinemenet node generated from them
 */
int Refiner::get_new_refine_node_owner(const std::vector<id_type>& node_group)
{
	bool on_interface = get_mesh()->nodes_on_part_interface(node_group);

	if (!on_interface)
		return get_mesh()->get_rank();
	else
	{
		// Same logic as in enrichment node addition here
		// If the owner of the lowest node id will also have a copy of this refinement node, then that parttion owns the refinement node
		// If the owner of the lowest id does not have a copy of this refinement node then the lowest partition that does will get ownership
		int owner = get_mesh()->get_node_owner_global(node_group[0]);
		std::vector<int> common_parts = get_mesh()->partitions_in_common(node_group);
		bool lowest_owner = (std::find(common_parts.begin(), common_parts.end(), owner) != common_parts.end());
		if (lowest_owner)
			return owner;
		else
			return *(std::min_element(common_parts.begin(), common_parts.end()));
	}
		
}




/*
 * Refine a general set of active elements. These are local element ids
 */
void Refiner::refine_elements(const std::set<id_type>& refined_elements)
{
	// Creates a set of node groups. Each node group represents a new node that will be added to the mesh.
	std::set<std::vector<id_type> > new_node_groups;
	generate_new_node_groups(refined_elements, new_node_groups);

	// Create all of the new nodes from the node groups
	create_new_nodes(new_node_groups);

	// Actually create all of the new elements now
	create_new_elements(refined_elements);

	// Gather any global information regarding the global mesh
	determine_global_information();
}




/*
 * Creates a set of node groups. Each node group represents a new node that will be added to the mesh.
 */
void Refiner::generate_new_node_groups(const std::set<id_type>& refined_elements,
									   std::set<std::vector<id_type> >& new_node_groups)
{
	// Loop over all refined elements and add their refinemenet node groups
	for (auto it=refined_elements.begin(), end=refined_elements.end(); it!=end; ++it)
	{
		// Get the normal nodes associated with each of the new refinement node
		std::vector<std::vector<id_type> > refinement_nodes;
		get_mesh()->get_elem_local(*it)->refinement_nodes(refinement_nodes);

		// Sort vectors for and insert into the set (to maintain uniqueness)
		for (id_type i=0; i<refinement_nodes.size(); ++i)
		{
			std::sort(refinement_nodes[i].begin(), refinement_nodes[i].end());

			// Only add this node to the set if it doesn't already exist from previous refinement
			if (get_mesh()->_refine_node_neighbors.find(refinement_nodes[i]) == get_mesh()->_refine_node_neighbors.end())
				new_node_groups.insert(refinement_nodes[i]);
		}
	}

	// If this is in parallel then I need to do some extra work associated with
	// communicatin node groups that occur along partition boundaries
	if (!get_mesh()->serial())
		communicate_new_node_groups(new_node_groups);
}



/*
 * If this is being run in parallel then communicate the node groups
 * that exist entirely along partition interfaces
 */
void Refiner::communicate_new_node_groups(std::set<std::vector<id_type> >& new_node_groups)
{
	// For every new node set, determine if I will own the new node
	//	-This is defined by:
	//		1. At least one node in the associated node group are fully within my partition
	//		2. If all nodes are on a partition interface then whichever partition owns the node
	//			with the lowest id owns the new node (does this work for face nodes???)
	// Also serialize the node groups on a partition interface for communication to neighboring procs
	std::map<int, id_type> curr_inds;
	std::map<int, std::vector<id_type> > nset_ptr_send;
	std::map<int, std::vector<id_type> > nset_ind_send;
	// Add an empty vector of additional elements to the remote structure for every processor I neighbor
	for (auto it=get_mesh()->_proc_neighbors.begin(), end=get_mesh()->_proc_neighbors.end(); it!=end; ++it)
	{
		nset_ptr_send.insert(std::pair<int, std::vector<id_type> >(*it, std::vector<id_type>(1, 0)));
		nset_ind_send.insert(std::pair<int, std::vector<id_type> >(*it, std::vector<id_type>()));
	}
	for (auto it=new_node_groups.begin(), end=new_node_groups.end(); it!=end; ++it)
	{
		const std::vector<id_type>& node_group = (*it);
		// Check whether or not I actually will own this node
		// If any points are not on a partition interface then its inside my material (Don't have to worry about weird cases like in add enrichments because these came from an element that I own...)
		// If all nodes are on a partition interface then if I own the node with the lowest global id. 
		bool on_interface = true;
		for (id_type n=0; n<node_group.size(); ++n)
			if (!get_mesh()->node_on_part_interface(node_group[n]))
			{
				on_interface = false;
				break;
			}

		if (on_interface)
		{
			// Find the set intersection of each of the partition lists for this node
			std::vector<int> common_parts = get_mesh()->partitions_in_common( node_group );

			// Add the neighbor list to every partition in the partition list
			for (id_type p=0; p<common_parts.size(); ++p)
			{
				int part = common_parts[p];
				if (part != get_mesh()->get_rank())
				{
					nset_ind_send[part].insert(nset_ind_send[part].end(), node_group.begin(), node_group.end());
					curr_inds[part] += node_group.size();
					nset_ptr_send[part].push_back(curr_inds[part]);
				}
			}
		}
	}

	// Send and recieve the serialized information
	// If any of the new node groups aren't already known then add them to the set
	MPI_Request reqs[2*(nset_ptr_send.size()-1)];
	id_type message = 0;
	for (auto it=nset_ptr_send.begin(), end=nset_ptr_send.end(); it!=end; ++it)
	{
		int part = it->first;
		if (part == get_mesh()->get_rank())
			continue;
		MPI_Isend((*it).second.data(), (*it).second.size(), MPI_ID, part, 0, get_mesh()->get_comm(), &reqs[2*message]);
		MPI_Isend(nset_ind_send[part].data(), nset_ind_send[part].size(), MPI_ID, part, 1, get_mesh()->get_comm(), &reqs[2*message+1]);
		message++;
	}
	for (auto it=get_mesh()->_proc_neighbors.begin(), end=get_mesh()->_proc_neighbors.end(); it!=end; ++it)
	{
		int part = *it;
		if (part == get_mesh()->get_rank())
			continue;

		std::vector<id_type> nset_ptr_recv_vec, nset_ind_recv_vec;
		Utilities::RecieveUnknown(nset_ptr_recv_vec, part, 0, MPI_ID, get_mesh()->get_comm());
		Utilities::RecieveUnknown(nset_ind_recv_vec, part, 1, MPI_ID, get_mesh()->get_comm());
		for (id_type n=0; n<(nset_ptr_recv_vec.size()-1); ++n)
		{
			id_type start = nset_ptr_recv_vec[n];
			id_type stop = nset_ptr_recv_vec[n+1];
			std::vector<id_type> new_vec(nset_ind_recv_vec.begin()+start, nset_ind_recv_vec.begin()+stop);

			// add it to the new set list
			new_node_groups.insert(new_vec);
		}
	}

	// MPI Cleanup
	MPI_Waitall(2*(nset_ptr_send.size()-1), reqs, MPI_STATUSES_IGNORE);
}



/*
 * Create all of the new nodes from the node groups
 */
void Refiner::create_new_nodes(const std::set<std::vector<id_type> >& new_node_groups)
{
	// Create all of the new nodes that I own. This just means finding the new coordinates. IDs will come next.
	allocate_new_nodes(new_node_groups);

	// Set the node ids for the nodes that I own
	set_new_node_ids(new_node_groups);

	// If this is in parallel then I need to communicate id information about the nodes I didn't own
	if (!get_mesh()->serial())
		communicate_new_node_ids(new_node_groups);

	// Add the newly created nodes to the appropriate node sets
	add_new_nodes_to_nodesets(new_node_groups);

	// Finally, detect all of the new nodes (in an IGFEM mesh)
	detect_new_nodes(new_node_groups);
}




/*
 * Actually find the coordinates of the new nodes and create the node objects
 */
void Refiner::allocate_new_nodes(const std::set<std::vector<id_type> >& new_node_groups)
{
	for (auto it=new_node_groups.begin(), end=new_node_groups.end(); it!=end; ++it)
	{
		// Find the new coordinates by averaging the coords of the nodes in the associated node group
		std::vector<double> coords(3,0.0);
		int nn = (*it).size();
		for (id_type n=0; n<(*it).size(); ++n)
		{
			Node* node = get_mesh()->get_node_global((*it)[n]);
			coords[0] += (*node)(0);
			coords[1] += (*node)(1);
			coords[2] += (*node)(2);
		}
		Node* new_node = new Node(coords[0]/nn, coords[1]/nn, coords[2]/nn, 0); // Don't worry about the id yet
		get_mesh()->_nodes.push_back( new_node );

		// Set the owner
		get_mesh()->_node_owners.push_back( get_new_refine_node_owner(*it) );
	}
}




/*
 * Set the node ids for the nodes that I own
 */
void Refiner::set_new_node_ids(const std::set<std::vector<id_type> >& new_node_groups)
{
	// Set the new node ids for nodes that this partition owns
	// New node numbering starts at the end of the number of global nodes
	//	offset by the number of nodes owned by processors before this one (default is 0 for serial)
	id_type partial_sum = 0;
	if (!get_mesh()->serial())
	{
		id_type n = get_mesh()->n_local_nodes() - new_node_groups.size(); // Local node number of first new node
		id_type n_owned_new_nodes = std::count(get_mesh()->_node_owners.begin()+n, get_mesh()->_node_owners.end(), get_mesh()->get_rank());

		MPI_Scan(&n_owned_new_nodes, &partial_sum, 1, MPI_ID, MPI_SUM, get_mesh()->get_comm());
		partial_sum -= n_owned_new_nodes;
	}

	// Rehash maps used in Mesh
	get_mesh()->_refine_node_neighbors.rehash(std::ceil((get_mesh()->n_local_nodes() - get_mesh()->n_pre_refinement_nodes())
														 / get_mesh()->_refine_node_neighbors.max_load_factor()));
	get_mesh()->_global_to_local_node.rehash(std::ceil((get_mesh()->n_local_nodes())
														/ get_mesh()->_global_to_local_node.max_load_factor()));

	// Start Loop over new nodes
	id_type n = get_mesh()->n_local_nodes() - new_node_groups.size(); // Local node number
	id_type id_count = 0;
	for (auto it=new_node_groups.begin(), end=new_node_groups.end(); it!=end; ++it)
	{
		int owner = get_mesh()->get_node_owner_local(n); // Owner was set in the last function
		// If I own the node, then I need to set the global id
		if (owner == get_mesh()->get_rank())
		{
			// Set global id to node and associated structures
			id_type id = get_mesh()->n_global_nodes() + partial_sum + id_count;
			get_mesh()->_nodes[ n ]->set_id( id );
			get_mesh()->_global_to_local_node[ id ] = n;

			// Add the neighbor list to the nieghbors to refinement node map
			get_mesh()->_refine_node_neighbors[ *it ] = id;

			// Increment the ID count
			id_count++;
		} // end if (owner==rank)
		
		// Update the local node counter
		n++;
	}
}




/*
 * In parallel, communicate the global node ids of new nodes appearing on partition interfaces
 * Maintains consistent node numbering across mesh partitions
 */
void Refiner::communicate_new_node_ids(const std::set<std::vector<id_type> >& new_node_groups)
{
	std::map<int, id_type> curr_inds;
	std::map<int, id_type> n_expected;
	std::map<int, std::vector<id_type> > nptr_send;
	std::map<int, std::vector<id_type> > nind_send;
	id_type n = get_mesh()->n_local_nodes() - new_node_groups.size(); // Local node number
	for (auto it=new_node_groups.begin(), end=new_node_groups.end(); it!=end; ++it)
	{
		int owner = get_mesh()->get_node_owner_local(n); // Owner was set in the last loop
		// If I own the node, then I need to add it to my send structure if its on an interface
		if (owner == get_mesh()->get_rank())
		{
			id_type id = get_mesh()->get_node_local( n )->get_id(); // Should have been set last function

			// If the new node has more than one partition then it belongs to a partition interface
			std::vector<int> parts = get_mesh()->partitions_in_common ( *it );
			if (parts.size() > 1) // Belongs to an interface
			{
				// Add it to the _node_partition_interface structur
				get_mesh()->_node_partition_interface.insert(std::pair<id_type, std::vector<int> >(id, parts));

				// Add the nodal information to the send lists for other processors
				for (id_type p=0; p<parts.size(); ++p) // Loop over all of the partitions that wil; be getting a copy of this node
				{
					int part = parts[p];
					if (part != get_mesh()->get_rank())
					{
						if (nptr_send.find(parts[p]) == nptr_send.end()) // Make sure I at least have empty vectors to insert into
						{
							nptr_send.insert(std::pair<int, std::vector<id_type> >(parts[p], std::vector<id_type>(1, 0)));
							nind_send.insert(std::pair<int, std::vector<id_type> >(parts[p], std::vector<id_type>()));
						}

						// Add the node id
						nind_send[parts[p]].push_back(id);
						nind_send[parts[p]].insert(nind_send[parts[p]].end(), (*it).begin(), (*it).end()); // Add the list of neighbors to the ind vector

						// Update the current index for this partition
						curr_inds[parts[p]] += 1 + (*it).size();
						nptr_send[parts[p]].push_back( curr_inds[parts[p]] );
					}
				}
			} // end if (parts.size()>1)
		} // end if (owner==rank)

		// If I don't own the node then I need to expect the solution from the owner
		else
			n_expected[owner]++;
		
		// Update the local node counter
		n++;
	}


	// Send and recieve the nodal ids and neighbor groups
	MPI_Request reqs2[2*nptr_send.size()];
	int message = 0;
	for (auto it=nptr_send.begin(), end=nptr_send.end(); it!=end; ++it)
	{
		int part = (*it).first;
		MPI_Isend((*it).second.data(), (*it).second.size(), MPI_ID, part, 2, get_mesh()->get_comm(), &reqs2[2*message]);
		MPI_Isend(nind_send[part].data(), nind_send[part].size(), MPI_ID, part, 3, get_mesh()->get_comm(), &reqs2[2*message+1]);
		message++;
	}
	for (auto it=n_expected.begin(), end=n_expected.end(); it!=end; ++it)
	{
		int part = (*it).first;
		std::vector<id_type> nptr_recv_vec, nind_recv_vec;
		Utilities::RecieveUnknown(nptr_recv_vec, part, 2, MPI_ID, get_mesh()->get_comm());
		Utilities::RecieveUnknown(nind_recv_vec, part, 3, MPI_ID, get_mesh()->get_comm());
		if (nptr_recv_vec.size() != (it->second+1))
			err_message("Unexpected number of new node ids recieved");

		for (id_type n=0; n<(nptr_recv_vec.size()-1); ++n)
		{
			id_type start = nptr_recv_vec[n];
			id_type stop = nptr_recv_vec[n+1];
			id_type id = nind_recv_vec[start];
			std::vector<id_type> neighbors(nind_recv_vec.begin()+start+1, nind_recv_vec.begin()+stop);
			auto it = new_node_groups.find(neighbors);
			if (it != new_node_groups.end())
			{
				// Find which of my local nodes it is and set the correct id
				id_type l_node = std::distance(new_node_groups.begin(), it) + (get_mesh()->n_local_nodes() - new_node_groups.size());
				get_mesh()->_nodes[l_node]->set_id(id);
				get_mesh()->_global_to_local_node[id] = l_node;

				// Add the neighbors list to the refinement node neighbors structure
				get_mesh()->_refine_node_neighbors[neighbors] = id;

				// Any node recieved is be default on a partition so add it to the node partition interface structure
				std::vector<int> parts = get_mesh()->partitions_in_common ( neighbors );
				get_mesh()->_node_partition_interface.insert(std::pair<id_type, std::vector<int> >(id, parts));
			}
			else
				err_message("Unknown neighbor list recieved");
		}
	}

	// MPI Cleanup
	MPI_Waitall(2*nptr_send.size(), reqs2, MPI_STATUSES_IGNORE);
}




/*
 * Add the newly created nodes to the appropriate node sets
 */
void Refiner::add_new_nodes_to_nodesets(const std::set<std::vector<id_type> >& new_node_groups)
{
	// Get all of the nodesets that I need to add this node to (If all of the nodes in a neighbor list belong to a set then the new node also should belong to that set)
	id_type n = get_mesh()->n_local_nodes() - new_node_groups.size(); // Local node number
	for (auto it=new_node_groups.begin(), end=new_node_groups.end(); it!=end; ++it)
	{
		id_type id = get_mesh()->get_node_local( n )->get_id();

		// Get all of the nodesets that I need to add this node to (If all of the nodes in a neighbor list belong to a set then the new node also should belong to that set)
		std::set<std::string> nodesets, temp_intersect;
		std::vector<std::set<std::string> > possible_sets(it->size());
		for (id_type n2=0; n2<(*it).size(); ++n2)
			for (Mesh::nodeset_iterator it2=get_mesh()->nodesets_begin(), end2=get_mesh()->nodesets_end(); it2!=end2; ++it2)
				if ((*it2).second.find((*it)[n2]) != (*it2).second.end()) // The current nodeset contains the current neighbor node
					possible_sets[n2].insert(it2->first);

		nodesets = possible_sets[0];
		for (id_type n2=1; n2<(*it).size(); ++n2)
		{
			std::set_intersection(nodesets.begin(), nodesets.end(),
								  possible_sets[n2].begin(), possible_sets[n2].end(),
								  std::inserter(temp_intersect, temp_intersect.begin()));
			nodesets.swap(temp_intersect);
			temp_intersect.clear();
		}
		// Now actually add the node to the nodeset
		for (auto it2=nodesets.begin(), end2=nodesets.end(); it2!=end2; ++it2)
			get_mesh()->add_to_nodeset(*it2, id);

		// Update the local node counter
		n++;
	}
}




/*
 * Detect all of the new nodes (in an IGFEM mesh)
 */
void Refiner::detect_new_nodes(const std::set<std::vector<id_type> >& new_node_groups)
{
	if (get_mesh()->IGFEM())
	{
		std::unordered_map<id_type, Inclusion*> nodes_to_reprocess;
		id_type n = get_mesh()->n_local_nodes() - new_node_groups.size(); // Local node number
		get_mesh()->_node_detect.resize( get_mesh()->n_local_nodes() );
		for (auto it=new_node_groups.begin(), end=new_node_groups.end(); it!=end; ++it)
		{
			// Do the nodal detection
			int ret = get_mesh()->detect_node( get_mesh()->get_node_local(n) );
			get_mesh()->_node_detect[n] = ret;

			// If the node lies on an inclusion surface and is also on a partition interface we must move it later
			if (ret >= (int)get_mesh()->n_inclusions())
				nodes_to_reprocess[n] = get_mesh()->_inclusions[ret - get_mesh()->n_inclusions()];

			// Update the local node counter
			n++;
		}

		// Reprocess the particularly annoying nodes
		get_mesh()->reprocess_nodes( nodes_to_reprocess );
	}
}




/*
 * Actually create the new elements from the given set of elements to be refined
 */
void Refiner::create_new_elements(const std::set<id_type>& refined_elements)
{
	// Figure out how many new elements I'm going to be adding
	id_type n_orig_elem = get_mesh()->n_local_elem(); // Store the number of elements at the beginning of this refinement step
	id_type n_new_elem = 0;
	for (auto it=refined_elements.begin(), end=refined_elements.end(); it!=end; ++it) // Get the number of new elements that will be added to the mesh
		n_new_elem += get_mesh()->get_elem_local(*it)->n_refinement_elem();
	
	// Global reduction to find the appropriate ids for the new elements
	id_type partial_sum = 0;
	if (!get_mesh()->serial())
	{
		MPI_Scan(&n_new_elem, &partial_sum, 1, MPI_ID, MPI_SUM, get_mesh()->get_comm());
		partial_sum -= n_new_elem;
	}

	// Rehash the g2l map
	get_mesh()->_global_to_local_elem.rehash( std::ceil((n_orig_elem + n_new_elem)
														 / get_mesh()->_global_to_local_elem.max_load_factor()) );

	// Loop over all old elemnts and create new children
	id_type id_count = 0;
	for (auto it=refined_elements.begin(), end=refined_elements.end(); it!=end; ++it)
	{
		id_type parent_l_elem = *it;
		Elem* parent_el = get_mesh()->get_elem_local( parent_l_elem );
		id_type n_parent_nodes = parent_el->n_nodes();
		std::vector<elem_type> refined_types;
		std::vector<std::vector<id_type> > refined_struct;
		std::vector<std::vector<id_type> > refinement_nodes;

		// Get all of the element sets that the parent belongs to
		std::set<std::string> sets_to_add;
		for (Mesh::elemset_iterator it2=get_mesh()->elemsets_begin(), end2=get_mesh()->elemsets_end(); it2!=end2; ++it2)
			if (it2->second.find(parent_el->get_id()) != it2->second.end()) //current set contains the element
				sets_to_add.insert(it2->first); // Add the set name to the list of sets to add to

		// Get all of the information from the parent element
		parent_el->refinement_nodes(refinement_nodes);
		parent_el->refinement_structure(refined_struct, refined_types);

		// Match this element's refinement nodes to the mesh's refienement nodes (newly generated or from a previous refienement)
		std::vector<id_type> refine_l_nodes(refinement_nodes.size(), 0);
		for (id_type n=0; n<refinement_nodes.size(); ++n)
		{
			std::sort(refinement_nodes[n].begin(), refinement_nodes[n].end());
			refine_l_nodes[n] = get_mesh()->global_to_local_node( get_mesh()->get_refine_node_from_neighbors(refinement_nodes[n]) );
		}

		// Generate new elements and add conectivity for them
		for (id_type e=0; e<refined_struct.size(); ++e)
		{
			// Generate element and associated structures
			Elem* new_el = Elem::build(refined_types[e]);
			id_type child_l_elem = get_mesh()->_elem.size();
			get_mesh()->_elem.push_back( new_el );
			get_mesh()->_elem_parents.push_back( parent_l_elem );
			get_mesh()->_elem_activity.push_back(true);
			get_mesh()->_p_level.push_back( get_mesh()->get_p_level_local(parent_l_elem) + 1 );
			get_mesh()->_elem_node.push_back( std::vector<id_type>(refined_struct[e].size(), 0) );
			get_mesh()->_elem_to_material.push_back(get_mesh()->get_mat_num_local(parent_l_elem));

			// Fill in the nodal connectivity table entry
			for (id_type n=0; n<refined_struct[e].size(); ++n)
			{
				id_type l_node = 0;
				if (refined_struct[e][n] < n_parent_nodes) // This is one of the element's original nodes
					l_node = get_mesh()->_elem_node[parent_l_elem][refined_struct[e][n]];
				else // This is a newly generated node
					l_node = refine_l_nodes[refined_struct[e][n] - n_parent_nodes];

				get_mesh()->_elem_node[child_l_elem][n] = l_node;
				new_el->set_node(n) = get_mesh()->get_node_local( l_node );
			}

			// Set the global_id
			id_type new_id = get_mesh()->n_global_elem() + partial_sum + id_count;
			new_el->set_id(new_id);
			get_mesh()->_global_to_local_elem[new_id] = child_l_elem;
			id_count++;

			// Add this element to the correct sets
			for (auto it2=sets_to_add.begin(), end2=sets_to_add.end(); it2!=end2; ++it2)
				get_mesh()->add_to_elemset((*it2), new_id);
		}

		// Set the parent element as inactive
		get_mesh()->_elem_activity[parent_l_elem] = 0;
	}

	// Refill the active elements vector
	get_mesh()->set_active_elements();
}




/*
 * Gather any global information regarding the global mesh
 */
void Refiner::determine_global_information()
{
	if (get_mesh()->serial())
	{
		get_mesh()->_n_local_owned_nodes = std::count(get_mesh()->_node_owners.begin(), get_mesh()->_node_owners.end(), 0);
		get_mesh()->_n_global_nodes = get_mesh()->n_local_nodes();
		get_mesh()->_n_global_elem = get_mesh()->n_local_elem();
		get_mesh()->_n_global_active_elem = get_mesh()->n_local_active_elem();
	}
	else
	{
		get_mesh()->_n_local_owned_nodes = std::count(get_mesh()->_node_owners.begin(), get_mesh()->_node_owners.end(), get_mesh()->get_rank());
		id_type n_l_elem = get_mesh()->n_local_elem();
		id_type n_l_active_elem = get_mesh()->n_local_active_elem();
		MPI_Allreduce(&get_mesh()->_n_local_owned_nodes, &get_mesh()->_n_global_nodes, 1, MPI_ID, MPI_SUM, get_mesh()->get_comm());
		MPI_Allreduce(&n_l_elem, &get_mesh()->_n_global_elem, 1, MPI_ID, MPI_SUM, get_mesh()->get_comm());
		MPI_Allreduce(&n_l_active_elem, &get_mesh()->_n_global_active_elem, 1, MPI_ID, MPI_SUM, get_mesh()->get_comm());
	}
}




/*
 * Will be called after the mesh is refined to interpolate the current solution field
 * Handles solution field as well as quadrature point internal variables
 */
void Refiner::interpolate_solution()
{

}




/*
 * Enforces the restriction that neighboring elements cannot be more than 1 p-level different
 */
void Refiner::enforce_p_level_constraint(std::set<id_type>& refined_elements)
{
	// Start by looping over all of the elements that are to be refined and find any p-level restrictions
	std::set<id_type> new_elements;
	new_elements.swap( refined_elements );
	bool continue_searching = true;
	while(continue_searching)
	{
		std::map<int, std::vector<id_type> > remote_additions;
		find_local_p_level_additions(refined_elements, new_elements, remote_additions);

		// If the mesh is serial then I've found all of the p-level additions
		if (get_mesh()->serial())
			continue_searching = false;

		// If the mesh isn't serial, I could get new eleents to refine from a remote
		// processor which could lead me to find more on my local partition
		else
		{
			std::set<id_type> new_local_elements;
			communicate_new_remote_elements(refined_elements, new_local_elements, remote_additions);

			// If any processor got new elements then I should continue searching the whole mesh
			bool continue_searching_local = false;
			if (new_local_elements.size() != 0)
			{
				continue_searching = true;
				new_elements.swap(new_local_elements); // Swap with the set of elements that I should begin my search with next time
			}
			MPI_Allreduce(&continue_searching_local, &continue_searching, 1, MPI_C_BOOL, MPI_LOR, get_mesh()->get_comm());
		}
	}
}




/*
 * Adds to the set refined_elements all those elements that break the p-level restriction
 * starting from the elements in the new_elements set. Also adds lists of new remote elements
 * that should be refined in parallel
 */
void Refiner::find_local_p_level_additions(std::set<id_type>& refined_elements, std::set<id_type>& new_elements,
										   std::map<int, std::vector<id_type> >& remote_additions)
{
	// Add an empty vector of additional elements to the remote structure for every processor I neighbor
	for (auto it=get_mesh()->_proc_neighbors.begin(), end=get_mesh()->_proc_neighbors.end(); it!=end; ++it)
		remote_additions.insert(std::pair<int, std::vector<id_type> >(*it, std::vector<id_type>()));

	// Loop over all of the new elements and find any p-level restrictions
	std::set<id_type> p_neighbors;
	while (new_elements.size()>0)
	{
		// Add all of the new eleents to the total list
		refined_elements.insert(new_elements.begin(), new_elements.end());

		// Loop over all new elements and find their enriched neighbors
		for (auto it=new_elements.begin(), end=new_elements.end(); it!=end; ++it)
		{
			// Get the local element number
			id_type l_elem = *it;
			Elem* el = get_mesh()->get_elem_local(l_elem);

			// Loop over all of the element's nodes
			for (id_type n=0; n<el->n_nodes(); ++n)
			{
				// If this node is a hanging node
				id_type id = el->get_node(n)->get_id();
				if (get_mesh()->is_hanging_node( id ))
				{
					// Find the neighbors of this hanging node
					std::vector<id_type>& neighbors = get_mesh()->get_hanging_node_neighbors(id);

					// Find all local elements that have these neighbors in common
					std::vector<id_type> common_elem = get_mesh()->local_elem_in_common(neighbors);
					for (id_type i=0; i<common_elem.size(); ++i)
						common_elem[i] = get_mesh()->global_to_local_elem(common_elem[i]);
					// Add these elements to the elements to be refined
					p_neighbors.insert(common_elem.begin(), common_elem.end());

					// Find all remote elements that have these nodes in common (Won't do anything in serial)
					std::map<int, std::vector<id_type> > remote_common_elem = get_mesh()->remote_elem_in_common(neighbors);
					for (auto it2=remote_common_elem.begin(), end2=remote_common_elem.end(); it2!=end2; ++it2)
					{
						std::vector<id_type>& my_vec = remote_additions[it2->first];
						my_vec.insert(my_vec.end(), it2->second.begin(), it2->second.end());
					}
				}
			}
		}

		// Find the set difference
		new_elements.clear();
		std::set_difference(p_neighbors.begin(), p_neighbors.end(),
							refined_elements.begin(), refined_elements.end(), 
	                    	std::inserter(new_elements, new_elements.begin()));
		p_neighbors.clear();
	}
}




/*
 * Communicates to all neighboring mesh partitions those elements which should be refined
 * based on criteria present on remote partitions. Stores all of these new elements in the
 * new_local_elements set
 */
void Refiner::communicate_new_remote_elements(const std::set<id_type>& refined_elements, std::set<id_type>& new_local_elements,
											  std::map<int, std::vector<id_type> >& remote_additions)
{
	// Add empty vectors to the send and recv structures for neighboring parittions that don't already have an entry
	for (auto it=get_mesh()->_proc_neighbors.begin(), end=get_mesh()->_proc_neighbors.end(); it!=end; ++it)
		if (remote_additions.find(*it) == remote_additions.end())
			remote_additions.insert(std::pair<int, std::vector<id_type> >(*it, std::vector<id_type>()));

	// Send all of the remote neighbors that I found
	MPI_Request reqs[get_mesh()->_proc_neighbors.size()];
	id_type message = 0;
	for (auto it=remote_additions.begin(), end=remote_additions.end(); it!=end; ++it)
		MPI_Isend((*it).second.data(), (*it).second.size(), MPI_ID, it->first, 0, get_mesh()->get_comm(), &reqs[message++]);


	// Recieve all of the remote neighbors that I should get and determine if any of them are new and if they are intersected
	for (auto it=remote_additions.begin(), end=remote_additions.end(); it!=end; ++it)
	{
		int part = it->first;
		std::vector<id_type> elem_recv_vec;
		Utilities::RecieveUnknown(elem_recv_vec, part, 0, MPI_ID, get_mesh()->get_comm());

		for(id_type i=0; i<elem_recv_vec.size(); ++i)
		{
			id_type l_elem = get_mesh()->global_to_local_elem(elem_recv_vec[i]);
			if (refined_elements.find(l_elem) == refined_elements.end())  // Don't already have it in the set of refined elements
				new_local_elements.insert(l_elem);
		}
	}
}